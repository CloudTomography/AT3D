{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactored Script: MultiView/MultiWavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import shdom\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "shdom.util.set_pyshdom_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Medium\n",
    "\n",
    "Decide on the individual scatterers and decide on the RTE grid that will be used.\n",
    "This must be done before sensor definition in the case of orthographic sensors\n",
    "and will also help decide general sensor pointing directions etc so should be the first step.\n",
    "\n",
    "Some utility functions from shdom.grid are used to combine the grids but these could be defined arbitrarily.\n",
    "\n",
    "All of the workflow, including this first step is based on the use of SHDOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a cloud.\n",
    "#locate the 'origin' of the cloud at 0.0,0.0 for simplicity.\n",
    "#this option allows us to easily move individual clouds with respect to each other\n",
    "#and even if overlapping they will be merged onto the RTE grid.\n",
    "cloud_scatterer = shdom.grid.load_from_csv('./synthetic_cloud_fields/jpl_les/rico32x37x26.txt', \n",
    "                                           density='lwc',origin=(0.0,0.0))\n",
    "\n",
    "#load atmosphere file for rayleigh. (and eventually gases)\n",
    "#'Altitude' coordinate is renamed to 'z'.\n",
    "atmosphere = xr.open_dataset('./ancillary_data/AFGL_summer_mid_lat.nc').rename(Altitude='z')\n",
    "\n",
    "#extract a chosen temperature_profile and the surface_pressure.\n",
    "#only model atmosphere below 20 km. This choice needs to be made here so\n",
    "#that an RTE grid can be defined.\n",
    "\n",
    "#try where with drop.na\n",
    "reduced_atmosphere = atmosphere.sel({'z': atmosphere.coords['z'].data[atmosphere.coords['z'].data <= 10.0]})\n",
    "\n",
    "# -----  make the RTE grid ---------------------------\n",
    "\n",
    "#make RTE grid just using cloud_scatterer for horizontal grid and 'merged' z coordinates.\n",
    "merged_z_coordinate = shdom.grid.combine_z_coordinates([reduced_atmosphere,cloud_scatterer])\n",
    "\n",
    "#simple 'union' horizontal grid merging for 3D and 1D needs to be fixed.\n",
    "rte_grid = shdom.grid.make_grid(cloud_scatterer.x.data.min(),cloud_scatterer.x.data.max(),cloud_scatterer.x.data.size,\n",
    "                           cloud_scatterer.y.data.min(),cloud_scatterer.y.data.max(),cloud_scatterer.y.data.size,\n",
    "                           merged_z_coordinate)\n",
    "\n",
    "#TODO \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resample the cloud onto the rte_grid\n",
    "cloud_scatterer_on_rte_grid = shdom.grid.resample_onto_grid(rte_grid, cloud_scatterer)\n",
    "\n",
    "#define any necessary variables for microphysics here.\n",
    "size_distribution_function = shdom.size_distribution.gamma\n",
    "\n",
    "#We choose a gamma size distribution and therefore need to define a 'veff' variable.\n",
    "cloud_scatterer_on_rte_grid['veff'] = xr.full_like(cloud_scatterer_on_rte_grid.reff, 0.1)\n",
    "\n",
    "shdom.grid.to_2parameter_lwc_file('./synthetic_cloud_fields/jpl_les/fixed_rico32x37x26.txt', cloud_scatterer_on_rte_grid, reduced_atmosphere)\n",
    "\n",
    "#new = shdom.grid.load_2parameter_lwc_file('/Users/jesserl2/fixed_rico32x37x26.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Sensors\n",
    "\n",
    "Individual sensors should be added and appended to a list. Any combination can be created.\n",
    "To illustrate a little of the variety we have an idealization of a MISR/MODIS or MSPI/eMAS type configuration with multi-view VIS and nadir-view multi-spectral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is modified by the user as needed.\n",
    "\n",
    "#idealized monochromatic orthographic sensors at different wavelengths.\n",
    "#9 'MISR-like' VIS cameras\n",
    "#1 'MODIS-like' nadir multi-spectral sensor.\n",
    "\n",
    "#TODO make this defined as a dict with entries for each 'instrument' to group sensors\n",
    "Sensordict = OrderedDict()\n",
    "\n",
    "misr_list = []\n",
    "\n",
    "#add MISR-like sensors\n",
    "sensor_zenith_list = [75.0,70.6]#,65.0,60.0,55.0,50.0,45.6,40.0,35.0,30.0,26.1,20.0,15.0,10.0,5.0]*2 + [0.0]\n",
    "sensor_azimuth_list = [90]*2 #+ [-90]*15 +[0.0]\n",
    "\n",
    "for zenith,azimuth in zip(sensor_zenith_list,sensor_azimuth_list):\n",
    "    misr_list.append(\n",
    "        shdom.sensor.add_sub_pixel_rays(shdom.sensor.orthographic_projection(1.65, cloud_scatterer,0.02,0.02, azimuth, zenith,\n",
    "                                             altitude='TOA', stokes='I'\n",
    "                                            ),FOV=1.0,degree=2)\n",
    "    \n",
    "    )\n",
    "    \n",
    "Sensordict['MISR'] = {'sensor_list': misr_list}\n",
    "  \n",
    "modis_list = []\n",
    "#add MODIS-like sensors\n",
    "wavelength_list = [1.65,2.17]\n",
    "for wavelength in wavelength_list:\n",
    "    modis_list.append(\n",
    "        shdom.sensor.add_sub_pixel_rays(shdom.sensor.orthographic_projection(wavelength,cloud_scatterer,0.02,0.02,0.0,0.0,\n",
    "                                            altitude='TOA',\n",
    "                                            stokes='I'\n",
    "                                            ),1.0,degree=2)\n",
    "    )\n",
    "    \n",
    "Sensordict['MODIS'] = {'sensor_list': modis_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forward_sensors(sensors):\n",
    "    \n",
    "    forward_sensors = OrderedDict()\n",
    "    for key,sensor in sensors.items():\n",
    "        forward_sensor= OrderedDict()\n",
    "        forward_sensor['sensor_list'] = [single_sensor.copy(deep=True) for single_sensor in sensor['sensor_list']]\n",
    "        forward_sensors[key] = forward_sensor\n",
    "        \n",
    "    return forward_sensors\n",
    "\n",
    "\n",
    "forward_sensors = make_forward_sensors(Sensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Number of SHDOM solvers.\n",
    "\n",
    "Here we need to choose the type (number of stokes components) and number (for different wavelengths) of SHDOM solvers. In this case we only have monochromatic sensors so the choice of SHDOMs is very simple and can be fixed/reused code. \n",
    "The number of SHDOM solvers could be defined based on other unique criteria such as arbitrary combinations of different sources/surfaces or scatterers. Scripts of that form can easily be adapted from this.\n",
    "This is the most common desired workflow as all RTE solvers at different wavelengths correspond to the same physical situation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_stokes should be set to choose whether to use num_stokes=USER_SPECIFIED\n",
    "#even if only radiance needs to be simulated for accuracy reasons.\n",
    "num_stokes_override_flag = False\n",
    "num_stokes_override=3\n",
    "\n",
    "#TODO hand specify num_stokes as in the configuration file, for example (or manually)\n",
    "#Define the unique wavelengths from all sensors.\n",
    "\n",
    "#extract all unique_wavelengths\n",
    "#this treats even very slightly different wavelengths as unique.\n",
    "wavelengths = shdom.script_util.get_unique_wavelengths(Sensordict)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Other RTE inputs.\n",
    "\n",
    "These are determined by the unique identifier which is wavelength in this case.\n",
    "For simplicity all other inputs are wavelength invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = OrderedDict()\n",
    "surfaces = OrderedDict()\n",
    "sources = OrderedDict()\n",
    "numerical_parameters = OrderedDict()\n",
    "num_stokes = OrderedDict()\n",
    "\n",
    "for wavelength in wavelengths:\n",
    "    num_stokes[wavelength] = 1\n",
    "    names[wavelength] = None\n",
    "    surfaces[wavelength] = shdom.surface.fixed_lambertian_surface(albedo=0.01) #surface is wavelength independent.\n",
    "    sources[wavelength] = shdom.source.solar_source(145.0,0.0,solarflux=1.0)\n",
    "    numerical_parameters[wavelength] = shdom.configuration.get_config('./default_config.json') #all use defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Scatterer Optical Properties\n",
    "\n",
    "In this case we only have one mie scatterer. Each type of scatterer should be explicitly treated with its own section here.\n",
    "\n",
    "This is a key component of the 'set_state' workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making mie_table. . . may take a while.\n",
      "making mie_table. . . may take a while.\n"
     ]
    }
   ],
   "source": [
    "#resample the cloud onto the rte_grid\n",
    "cloud_scatterer_on_rte_grid = shdom.grid.resample_onto_grid(rte_grid, cloud_scatterer)\n",
    "\n",
    "#define any necessary variables for microphysics here.\n",
    "size_distribution_function = shdom.size_distribution.gamma\n",
    "#We choose a gamma size distribution and therefore need to define a 'veff' variable.\n",
    "cloud_scatterer_on_rte_grid['veff'] = (cloud_scatterer_on_rte_grid.reff.dims, \n",
    "                                       np.full_like(cloud_scatterer_on_rte_grid.reff.data, fill_value=0.1))\n",
    "\n",
    "#calculate the optical properties for this scatterer.\n",
    "#All wavelengths use consistent settings.\n",
    "cloud_poly_tables = OrderedDict()\n",
    "cloud_optical_scatterers = OrderedDict()\n",
    "for wavelength in wavelengths:\n",
    "    print('making mie_table. . . may take a while.')\n",
    "    mie_mono_table = shdom.mie.get_mono_table('Water',(wavelength,wavelength)) \n",
    "    cloud_size_distribution = shdom.size_distribution.get_size_distribution_grid(\n",
    "                                                            mie_mono_table.radius.data,\n",
    "                        size_distribution_function=size_distribution_function,particle_density=1.0,\n",
    "                        reff=[4.0,25.0,25,'logarithmic','micron'],\n",
    "                        veff=[0.09,0.11,2,'linear','unitless'],                                                                               \n",
    "                        )\n",
    "    poly_table = shdom.mie.get_poly_table(cloud_size_distribution,mie_mono_table)\n",
    "    cloud_optical_scatterers[wavelength] = shdom.medium.table_to_grid(cloud_scatterer_on_rte_grid, poly_table)\n",
    "    cloud_poly_tables[wavelength] = poly_table    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Rayleigh Optical Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rayleigh.\n",
    "#This is self contained due to its simplicity.\n",
    "rayleigh_scatterer_list = shdom.rayleigh.to_grid(wavelengths,atmosphere,rte_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO make this a function (combine scatterers to medium)\n",
    "mediums = shdom.script_util.combine_to_medium([cloud_optical_scatterers, rayleigh_scatterer_list])\n",
    "#group properties \n",
    "# mediums = OrderedDict()\n",
    "# for key,optical in cloud_optical_scatterers.items():\n",
    "    \n",
    "#     rayleigh = rayleigh_scatterer_list[key]\n",
    "#     mediums[key] = [optical]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make solver list\n",
    "solvers = OrderedDict()\n",
    "\n",
    "for key,name in names.items():\n",
    "    solvers[key] = shdom.solver.RTE(numerical_params=numerical_parameters[key], \n",
    "                                    medium=mediums[key],\n",
    "                                   source=sources[key],\n",
    "                                   surface=surfaces[key],\n",
    "                                    num_stokes=num_stokes[key],\n",
    "                                    name=name\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shdom.script_util.get_measurements(solvers, Sensordict, maxiter=2, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_unknowns = OrderedDict()\n",
    "for key, scatterer in cloud_optical_scatterers.items():\n",
    "    cloud_unknowns[key] = (scatterer, cloud_poly_tables[key], 'reff')\n",
    "    \n",
    "unordered_unknown_scatterers = [cloud_unknowns]\n",
    "unknown_scatterers = shdom.script_util.combine_to_medium(unordered_unknown_scatterers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_derivatives = shdom.gradient.create_derivative_tables(solvers, unknown_scatterers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers  = shdom.gradient.get_derivatives(solvers, table_derivatives)\n",
    "rte_sensors, sensor_mapping = shdom.script_util.sort_sensors(Sensordict, solvers, 'inverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'data_vars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d4b5357fcb94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m loss, gradient = shdom.gradient.levis_approx_uncorrelated_l2(\n\u001b[0;32m----> 2\u001b[0;31m     Sensordict, solvers, forward_sensors, unknown_scatterers, table_derivatives, n_jobs=1)\n\u001b[0m",
      "\u001b[0;32m~/Code/pyshdom_dev/shdom/gradient.py\u001b[0m in \u001b[0;36mlevis_approx_uncorrelated_l2\u001b[0;34m(measurements, solvers, forward_sensors, unknown_scatterers, table_derivatives, n_jobs, mpi_comm, verbose)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     loss, gradient = parallel_gradient(solvers, rte_sensors, sensor_mapping, forward_sensors, gradient_fun=grad_l2,\n\u001b[0;32m--> 447\u001b[0;31m                      mpi_comm=mpi_comm, n_jobs=n_jobs)\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m#Turn gradient into an xarray Dataset #TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/pyshdom_dev/shdom/gradient.py\u001b[0m in \u001b[0;36mparallel_gradient\u001b[0;34m(solvers, rte_sensors, sensor_mapping, forward_sensors, gradient_fun, mpi_comm, n_jobs)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             out = [shdom.gradient.gradient_one_solver(solvers[key],rte_sensors[key],render_jobs[key], sensor_mapping[key],\n\u001b[0;32m--> 474\u001b[0;31m                                                      forward_sensors, gradient_fun) for key in solvers.keys()]\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             out = Parallel(n_jobs=len(list(solvers.keys())), backend=\"threading\")(\n",
      "\u001b[0;32m~/Code/pyshdom_dev/shdom/gradient.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             out = [shdom.gradient.gradient_one_solver(solvers[key],rte_sensors[key],render_jobs[key], sensor_mapping[key],\n\u001b[0;32m--> 474\u001b[0;31m                                                      forward_sensors, gradient_fun) for key in solvers.keys()]\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             out = Parallel(n_jobs=len(list(solvers.keys())), backend=\"threading\")(\n",
      "\u001b[0;32m~/Code/pyshdom_dev/shdom/gradient.py\u001b[0m in \u001b[0;36mgradient_one_solver\u001b[0;34m(rte_solver, sensor, n_jobs, sensor_mapping, forward_sensors, gradient_fun)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;31m# TODO: fix this. the output of gradient_fun is a list of tuples with numpy arrays (see return of grad_l2: gradient, loss, integrated_rays)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mvar_list_nray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'rays_per_image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stokes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list_nray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'data_vars'"
     ]
    }
   ],
   "source": [
    "loss, gradient = shdom.gradient.levis_approx_uncorrelated_l2(\n",
    "    Sensordict, solvers, forward_sensors, unknown_scatterers, table_derivatives, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
